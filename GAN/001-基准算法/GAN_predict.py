# coding=utf-8
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import os

# ======================
# ğŸ“ 1. åŠ è½½æ¨¡å‹å’Œç¼©æ”¾å‚æ•°
# ======================
save_dir = r'C:\Users\1\Desktop\GAN\saved_models'
G_path = os.path.join(save_dir, 'generator_lag.pth')
scaler_x_path = os.path.join(save_dir, 'scaler_x.npy')
scaler_y_path = os.path.join(save_dir, 'scaler_y.npy')

# åŠ è½½ç¼©æ”¾å™¨å‚æ•°
scaler_x_params = np.load(scaler_x_path, allow_pickle=True).item()
scaler_y_params = np.load(scaler_y_path, allow_pickle=True).item()

scaler_x = StandardScaler()
scaler_x.mean_ = scaler_x_params['mean']
scaler_x.scale_ = scaler_x_params['scale']

scaler_y = StandardScaler()
scaler_y.mean_ = scaler_y_params['mean']
scaler_y.scale_ = scaler_y_params['scale']

# ======================
# ğŸ§  2. å®šä¹‰ç”Ÿæˆå™¨
# ======================
columns = ['T_SONIC', 'CO2_density', 'CO2_density_fast_tmpr',
           'H2O_density', 'H2O_sig_strgth', 'CO2_sig_strgth']

noise_columns = ['Error_T_SONIC', 'Error_CO2_density', 'Error_CO2_density_fast_tmpr',
                 'Error_H2O_density', 'Error_H2O_sig_strgth', 'Error_CO2_sig_strgth']

# æ»åç‰¹å¾ï¼ˆå¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
all_features = columns + noise_columns + [f'{col}_lag{lag}' for col in columns + noise_columns for lag in [1,2,3]]

class Generator(nn.Module):
    def __init__(self, input_dim=len(all_features), output_dim=len(columns)):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, output_dim)
        )
    def forward(self, x):
        return self.model(x)

# åŠ è½½æ¨¡å‹
G = Generator()
G.load_state_dict(torch.load(G_path))
G.eval()

print("âœ… æ¨¡å‹ä¸ç¼©æ”¾å™¨å·²åŠ è½½å®Œæ¯•ï¼Œå¯ä»¥è¿›è¡Œé¢„æµ‹ã€‚")

# ======================
# ğŸ“Š 3. åŠ è½½æµ‹è¯•æ•°æ®
# ======================
test_data = pd.read_csv(r'C:\Users\1\Desktop\MLæœŸæœ«\æ•°æ®é›†ï¼ˆå«çœŸå®å€¼ï¼‰\modified_æ•°æ®é›†Time_Series662.dat')

# --- æ·»åŠ æ»åç‰¹å¾ ---
def add_lag_features(df, cols, lags=[1,2,3]):
    df_lag = df.copy()
    for col in cols:
        for lag in lags:
            df_lag[f'{col}_lag{lag}'] = df_lag[col].shift(lag).bfill()
    return df_lag

test_data = add_lag_features(test_data, columns + noise_columns)

X_test = scaler_x.transform(test_data[all_features].values)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)

# ======================
# ğŸ”® 4. æ¨¡å‹é¢„æµ‹
# ======================
with torch.no_grad():
    Y_pred_scaled = G(X_test_tensor).numpy()
    Y_pred = scaler_y.inverse_transform(Y_pred_scaled)

# ======================
# ğŸ’¾ 5. ä¿å­˜é¢„æµ‹ç»“æœï¼ˆå…¼å®¹è¯„ä¼°è„šæœ¬ï¼‰
# ======================
# å°†æ¯ä¸€è¡Œçš„6ä¸ªé¢„æµ‹å€¼è½¬ä¸ºå­—ç¬¦ä¸²ï¼š '2.55 31.22 30.85 1.45 0.04 0.06'
pred_strs = [' '.join(map(str, row)) for row in Y_pred]
output_df = pd.DataFrame({'Predicted_Value': pred_strs})

output_path = r"C:\Users\1\Desktop\GAN\Output\GAN_lag_predictions.csv"
output_df.to_csv(output_path, index=False, encoding='utf-8-sig')

print(f"âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœè‡³ï¼š{output_path}")
print(output_df.head())
